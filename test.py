import datetime
import dateutil
from dateutil import parser
import requests
from bs4 import BeautifulSoup
import urllib.parse
import tldextract
import re
import sys
import json
from copy import deepcopy


def tableScraper():
    return None

def webParser(url):

    cpe_list=[]
    bulletin=[]
    vulnerabilities=[]

    page = requests.get(url)
    soup = BeautifulSoup(page.content, "html.parser")
    tables = soup.find_all("div", {"class": "table parbase section"})

    tableEnum = enumerate(tables)

    productName = ""
    startVersion = None
    endVersion = None

    for tableIndex, table in tableEnum:
        "<tr> tag defines a row in an HTML table."
        rows = table.find_all('tr')
        for row in rows:
            "<td> tag defines a standard data cell in an HTML table"
            cells = row.find_all('td')
            cells = [x.text.strip() for x in cells]

            if tableIndex == 0:
                bulletin.append(cells)

            elif tableIndex == 1:
                try:
                    vendor= cells[0].lower().split(" ")[0]
                    product = cells[0].lower().replace(vendor,"").strip()
                    productName = product
                    splitCells = cells[1].lower().split()
                    cpe_dict={
                        "vendor": vendor,
                        "product": product,
                        "category": "a"
                    }
                    if splitCells[1] and splitCells[1] != "and":
                        startVersion = splitCells[-1]
                        cpe_dict["versionStartIncluding"] = startVersion
                    endVersion = splitCells[0]
                    cpe_dict["versionEndIncluding"] = endVersion
                    cpe_list.append(cpe_dict)
                except:
                    continue
            elif tableIndex == 3:
                vulnerabilities.append(cells)

    dateDetails = bulletin[1][1]
    publishedDate = parser.parse(dateDetails).isoformat()

    CVEs = []

    cveIndex = [(vulnerabilities[0].index(x)) for x in vulnerabilities[0] if "CVE" in x]
    vulCategory = [(vulnerabilities[0].index(x)) for x in vulnerabilities[0] if "Vulnerability Category" in x]

    startVersionList = []

    for vul in vulnerabilities[1:]:
        #startVersionList.append(vul[4].split()[1])
        """
        i = 0
        if startVersion:
            startV = vul[4].split()[1]
            startVersionList.append(vul[4].split()[1])
            
            cpe_list[0]["versionStartIncluding"] = startV
            
            #cpe_dict["versionStartIncluding"] = startVersion
        """    
        #print(CVEs)
        #print(cpe_list)    
        now = datetime.datetime.now()
        timestamp = now.isoformat()

        description = vul[vulCategory[0]]

        id = vul[cveIndex[0]]
        name = productName         
        cve = {
            "timestamp": str(timestamp),
            "published_date": str(publishedDate),
            "id" : str(id),
            "url" : str(url),
            "name" : name,
            "description": str(description).lower(),
            "cpes": {
                "cpe_list" : cpe_list
            }
        }
        CVEs.append(cve)

    """
    CVEwithStartV = deepcopy(CVEs)
    #print(CVEwithStartV)


    if startVersion:
        print(CVEwithStartV[1]['cpes']['cpe_list'][0])
        CVEwithStartV[1]['cpes']['cpe_list'][0]['versionStartIncluding'] = '7.0'
        print(CVEwithStartV[1]['cpes']['cpe_list'][0])
        print(CVEwithStartV[2]['cpes']['cpe_list'][0])
        print(splitCells[-1])
        print(startVersion)
        #CVEs[3]['cpes']['cpe_list'][0]['versionStartIncluding'] = '8.0'
        #print(CVEs[1])
    #print(CVEs)
        #print(startVersionList)
    
    if startVersion:
        #print(len(CVEs))
        for i in range(len(CVEs)):
            print(CVEs[i]['cpes']['cpe_list'])
            #print(startVersionList[i])
            #CVEs[i]['cpes']['cpe_list'][0]['versionStartIncluding'] = startVersionList[i]
            CVEs[i]['cpes']['cpe_list'][0].update({'versionStartIncluding': startVersionList[i]})
            #print((CVEs[i]['cpes']['cpe_list'][0]['versionStartIncluding'], startVersionList[i]))
            #print(startVersionList[i])
    """
    

    ext = tldextract.extract(url)
    source = ext.domain            
    typ = "vendor"
    jsonOutput = {
        "source" : source,
        "type" : typ,
        "cves" : CVEs
    }

    outputFile = open('output.json', 'w')
    outputFile.write(json.dumps(jsonOutput, indent=4))
    outputFile.close()

    return jsonOutput

if __name__ == "__main__":

    inp_url = sys.argv[1]

    url = inp_url
    webParser(url)